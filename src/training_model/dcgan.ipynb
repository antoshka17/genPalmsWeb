{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f89120d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anton/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from gan import Generator\n",
    "from gan import Discriminator\n",
    "from gan import weights_init\n",
    "from dataset import HandDataset\n",
    "import cv2\n",
    "import timm\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "from gan import save_images, save_image\n",
    "from gan import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cac9454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>skinColor</th>\n",
       "      <th>accessories</th>\n",
       "      <th>nailPolish</th>\n",
       "      <th>aspectOfHand</th>\n",
       "      <th>imageName</th>\n",
       "      <th>irregularities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "      <td>fair</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dorsal right</td>\n",
       "      <td>Hand_0000002.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "      <td>fair</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dorsal right</td>\n",
       "      <td>Hand_0000003.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "      <td>fair</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dorsal right</td>\n",
       "      <td>Hand_0000004.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "      <td>fair</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dorsal right</td>\n",
       "      <td>Hand_0000005.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "      <td>fair</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dorsal right</td>\n",
       "      <td>Hand_0000006.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11071</th>\n",
       "      <td>1589</td>\n",
       "      <td>22</td>\n",
       "      <td>female</td>\n",
       "      <td>fair</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>palmar left</td>\n",
       "      <td>Hand_0011740.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11072</th>\n",
       "      <td>1589</td>\n",
       "      <td>22</td>\n",
       "      <td>female</td>\n",
       "      <td>fair</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>palmar left</td>\n",
       "      <td>Hand_0011741.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11073</th>\n",
       "      <td>1589</td>\n",
       "      <td>22</td>\n",
       "      <td>female</td>\n",
       "      <td>fair</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>palmar left</td>\n",
       "      <td>Hand_0011742.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11074</th>\n",
       "      <td>1589</td>\n",
       "      <td>22</td>\n",
       "      <td>female</td>\n",
       "      <td>fair</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>palmar left</td>\n",
       "      <td>Hand_0011743.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11075</th>\n",
       "      <td>1589</td>\n",
       "      <td>22</td>\n",
       "      <td>female</td>\n",
       "      <td>fair</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>palmar left</td>\n",
       "      <td>Hand_0011744.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11076 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  age  gender skinColor  accessories  nailPolish  aspectOfHand  \\\n",
       "0         0   27    male      fair            0           0  dorsal right   \n",
       "1         0   27    male      fair            0           0  dorsal right   \n",
       "2         0   27    male      fair            0           0  dorsal right   \n",
       "3         0   27    male      fair            0           0  dorsal right   \n",
       "4         0   27    male      fair            0           0  dorsal right   \n",
       "...     ...  ...     ...       ...          ...         ...           ...   \n",
       "11071  1589   22  female      fair            0           0   palmar left   \n",
       "11072  1589   22  female      fair            0           0   palmar left   \n",
       "11073  1589   22  female      fair            0           0   palmar left   \n",
       "11074  1589   22  female      fair            0           0   palmar left   \n",
       "11075  1589   22  female      fair            0           0   palmar left   \n",
       "\n",
       "              imageName  irregularities  \n",
       "0      Hand_0000002.jpg               0  \n",
       "1      Hand_0000003.jpg               0  \n",
       "2      Hand_0000004.jpg               0  \n",
       "3      Hand_0000005.jpg               0  \n",
       "4      Hand_0000006.jpg               0  \n",
       "...                 ...             ...  \n",
       "11071  Hand_0011740.jpg               0  \n",
       "11072  Hand_0011741.jpg               0  \n",
       "11073  Hand_0011742.jpg               0  \n",
       "11074  Hand_0011743.jpg               0  \n",
       "11075  Hand_0011744.jpg               0  \n",
       "\n",
       "[11076 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_path = 'archive/Hands/Hands'\n",
    "img_size = 256\n",
    "random_state = 69\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "z_size = 512\n",
    "\n",
    "df = pd.read_csv('archive/HandInfo.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "325a2702",
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = 4\n",
    "batch_size = 32\n",
    "image_size = 256\n",
    "nc = 3\n",
    "nz = 500\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "num_epochs = 300\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "469ee2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.27 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/home/anton/PycharmProjects/another_projects/bio/hand-palm-detection.v2i.yolov11/data.yaml, epochs=200, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda:0, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Dataset '/home/anton/PycharmProjects/another_projects/bio/hand-palm-detection.v2i.yolov11/data.yaml' error âŒ '/home/anton/PycharmProjects/another_projects/bio/hand-palm-detection.v2i.yolov11/data.yaml' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/trainer.py:557\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myml\u001b[39m\u001b[38;5;124m\"\u001b[39m} \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetect\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    556\u001b[0m }:\n\u001b[0;32m--> 557\u001b[0m     data \u001b[38;5;241m=\u001b[39m check_det_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/data/utils.py:269\u001b[0m, in \u001b[0;36mcheck_det_dataset\u001b[0;34m(dataset, autodownload)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03mDownload, verify, and/or unzip a dataset if not found locally.\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;124;03m    (dict): Parsed dataset information and paths.\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m file \u001b[38;5;241m=\u001b[39m check_file(dataset)\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m# Download (optional)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/utils/checks.py:520\u001b[0m, in \u001b[0;36mcheck_file\u001b[0;34m(file, suffix, download, download_dir, hard)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m files \u001b[38;5;129;01mand\u001b[39;00m hard:\n\u001b[0;32m--> 520\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(files) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m hard:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: '/home/anton/PycharmProjects/another_projects/bio/hand-palm-detection.v2i.yolov11/data.yaml' does not exist",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m yolo \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolo11n.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m yolo \u001b[38;5;241m=\u001b[39m yolo\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 4\u001b[0m res \u001b[38;5;241m=\u001b[39m yolo\u001b[38;5;241m.\u001b[39mtrain(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/anton/PycharmProjects/another_projects/bio/hand-palm-detection.v2i.yolov11/data.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m      6\u001b[0m results \u001b[38;5;241m=\u001b[39m yolo([os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ds_path, fn) \u001b[38;5;28;01mfor\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(ds_path)][:\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m      7\u001b[0m results\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/model.py:796\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    794\u001b[0m     args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path\n\u001b[0;32m--> 796\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m (trainer \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_smart_load(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrainer\u001b[39m\u001b[38;5;124m\"\u001b[39m))(overrides\u001b[38;5;241m=\u001b[39margs, _callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks)\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# manually set model only if not resuming\u001b[39;00m\n\u001b[1;32m    798\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/trainer.py:133\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[0;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m check_model_file_from_stem(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel)  \u001b[38;5;66;03m# add suffix, i.e. yolov8n -> yolov8n.pt\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch_distributed_zero_first(LOCAL_RANK):  \u001b[38;5;66;03m# avoid auto-downloading dataset multiple times\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtestset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_dataset()\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Optimization utils init\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/trainer.py:561\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# for validating 'yolo train data=url.zip' usage\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(emojis(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclean_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m error âŒ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m], data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dataset '/home/anton/PycharmProjects/another_projects/bio/hand-palm-detection.v2i.yolov11/data.yaml' error âŒ '/home/anton/PycharmProjects/another_projects/bio/hand-palm-detection.v2i.yolov11/data.yaml' does not exist"
     ]
    }
   ],
   "source": [
    "yolo = YOLO('yolo11n.pt')\n",
    "yolo = yolo.to(device)\n",
    "\n",
    "res = yolo.train(data='/home/anton/PycharmProjects/another_projects/bio/hand-palm-detection.v2i.yolov11/data.yaml', epochs=200)\n",
    "\n",
    "results = yolo([os.path.join(ds_path, fn) for fn in os.listdir(ds_path)][:3])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd929ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "'/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m yolo\u001b[38;5;241m.\u001b[39mval()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/model.py:635\u001b[0m, in \u001b[0;36mModel.val\u001b[0;34m(self, validator, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcustom, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m}  \u001b[38;5;66;03m# highest priority args on the right\u001b[39;00m\n\u001b[1;32m    634\u001b[0m validator \u001b[38;5;241m=\u001b[39m (validator \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_smart_load(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidator\u001b[39m\u001b[38;5;124m\"\u001b[39m))(args\u001b[38;5;241m=\u001b[39margs, _callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks)\n\u001b[0;32m--> 635\u001b[0m validator(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics \u001b[38;5;241m=\u001b[39m validator\u001b[38;5;241m.\u001b[39mmetrics\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m validator\u001b[38;5;241m.\u001b[39mmetrics\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/validator.py:144\u001b[0m, in \u001b[0;36mBaseValidator.__call__\u001b[0;34m(self, trainer, model)\u001b[0m\n\u001b[1;32m    141\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting batch=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input of shape (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, 3, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimgsz\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimgsz\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myml\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m check_det_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassify\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m check_cls_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msplit)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/data/utils.py:269\u001b[0m, in \u001b[0;36mcheck_det_dataset\u001b[0;34m(dataset, autodownload)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_det_dataset\u001b[39m(dataset, autodownload\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    255\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03m    Download, verify, and/or unzip a dataset if not found locally.\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;124;03m        (dict): Parsed dataset information and paths.\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m     file \u001b[38;5;241m=\u001b[39m check_file(dataset)\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m# Download (optional)\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     extract_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/utils/checks.py:520\u001b[0m, in \u001b[0;36mcheck_file\u001b[0;34m(file, suffix, download, download_dir, hard)\u001b[0m\n\u001b[1;32m    518\u001b[0m files \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;28mstr\u001b[39m(ROOT \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m file), recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;28mstr\u001b[39m(ROOT\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m/\u001b[39m file))  \u001b[38;5;66;03m# find file\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m files \u001b[38;5;129;01mand\u001b[39;00m hard:\n\u001b[0;32m--> 520\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(files) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m hard:\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiple files match \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, specify exact path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfiles\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: '/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml' does not exist"
     ]
    }
   ],
   "source": [
    "yolo.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5963219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    boxes = result.boxes\n",
    "    print(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea8b9e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11076/11076 [04:53<00:00, 37.79it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path_to_model = '/home/anton/PycharmProjects/another_projects/bio/best.pt'\n",
    "best_yolo = YOLO(path_to_model)\n",
    "\n",
    "if not Path('cropped_images').exists():\n",
    "    os.mkdir('cropped_images')\n",
    "    \n",
    "all_fns = [os.path.join(ds_path, fn) for fn in os.listdir(ds_path)]\n",
    "\n",
    "for fn in tqdm(all_fns):\n",
    "    result = best_yolo.predict(fn, show=False, verbose=False)\n",
    "    boxes = result[0].boxes.xyxy\n",
    "    if len(boxes) > 0:\n",
    "        x1, y1, x2, y2 = list(map(int, boxes.detach().cpu().numpy()[0]))\n",
    "    \n",
    "        img_name = fn.split('/')[-1]\n",
    "        img = cv2.imread(fn)\n",
    "        \n",
    "        x1, x2 = max(int(x1 - 0.2 * img.shape[1]), 0), min(int(x2 + 0.2 * img.shape[1]), img.shape[1] - 2)\n",
    "        y1, y2 = max(int(y1 - 0.2 * img.shape[0]), 0), min(int(y2 + 0.2 * img.shape[0]), img.shape[0] - 2)\n",
    "        new_image = img[y1:y2+1, x1:x2+1]\n",
    "        cv2.imwrite(os.path.join('cropped_images', img_name), new_image)\n",
    "        continue\n",
    "    \n",
    "    image = cv2.imread(fn)\n",
    "    img_name = fn.split('/')[-1]\n",
    "    cv2.imwrite(os.path.join('cropped_images', img_name), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e350d420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed(random_state):\n",
    "    torch.manual_seed(random_state)\n",
    "    torch.cuda.manual_seed(random_state)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e288d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = A.Compose([\n",
    "    A.Resize(img_size, img_size),\n",
    "#     A.VerticalFlip(p=0.6),\n",
    "#     A.HorizontalFlip(p=0.6),\n",
    "#     A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.6),\n",
    "#     A.Normalize(mean=0.5, std=0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a42f9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_path_ = 'cropped_images'\n",
    "dataset = HandDataset(ds_path_, df, transform=transforms)\n",
    "dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b240bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6db6460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "lr = 0.0002\n",
    "\n",
    "load = True\n",
    "\n",
    "generator = Generator(ngpu).to(device)\n",
    "# discriminator = timm.create_model('resnet18', pretrained=False, num_classes=2).to(device)\n",
    "discriminator = Discriminator(ngpu).to(device)\n",
    "weights_init(generator)\n",
    "weights_init(discriminator)\n",
    "\n",
    "if load:\n",
    "    generator.load_state_dict(torch.load('generator.pt'))\n",
    "    discriminator.load_state_dict(torch.load('discriminator.pt'))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "params = {\n",
    "    'generator': generator,\n",
    "    'discriminator': discriminator,\n",
    "    'train_dl': dataloader, \n",
    "    'criterion': criterion,\n",
    "    'lr': lr,\n",
    "    'device': device,\n",
    "    'epochs': num_epochs,\n",
    "    'generator_path': 'generator.pt',\n",
    "    'discriminator_path': 'discriminator.pt'\n",
    "}\n",
    "    \n",
    "trainer = Trainer(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4a8093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [02:46<00:00,  2.09it/s, loss_d=0.314, loss_g=1.55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|â–ˆâ–ˆâ–ˆâ–‹         | 100/347 [00:52<02:08,  1.92it/s, loss_d=0.0028, loss_g=10.6]"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93bd571c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [02:23<00:00,  2.42it/s, loss_d=0.0156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [02:28<00:00,  2.33it/s, loss_d=0.00407]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [02:29<00:00,  2.32it/s, loss_d=0.000308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [02:30<00:00,  2.30it/s, loss_d=0.000457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [02:30<00:00,  2.31it/s, loss_d=0.000145]\n"
     ]
    }
   ],
   "source": [
    "# generator = Generator(ngpu).to(device)\n",
    "# generator.load_state_dict(torch.load('generator.pt'))\n",
    "# generator.eval()\n",
    "# model_for_sampling = timm.create_model('resnet18', pretrained=True, num_classes=2).to(device)\n",
    "# optimizer = torch.optim.Adam(model_for_sampling.parameters(), lr=lr)\n",
    "\n",
    "# for epoch in range(5):\n",
    "#     print(f'epoch: {epoch + 1}')\n",
    "#     with tqdm(dataloader, total=len(dataloader), position=0, leave=True) as pbar:\n",
    "#         for i, data in enumerate(pbar):\n",
    "#             model_for_sampling.zero_grad()\n",
    "\n",
    "#             real_cpu = data.to(device)\n",
    "\n",
    "#             b_size = real_cpu.size(0)\n",
    "#             label = torch.LongTensor([1 for j in range(b_size)]).to(device)\n",
    "\n",
    "#             output = model_for_sampling(real_cpu)\n",
    "\n",
    "#             loss_d_real = criterion(output, label)\n",
    "\n",
    "#             loss_d_real.backward()\n",
    "#             D_x = output.mean().item()\n",
    "#             noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "#             fake = generator(noise)\n",
    "#             label.fill_(fake_label)\n",
    "#             output = model_for_sampling(fake.detach())\n",
    "\n",
    "#             loss_d_fake = criterion(output, label)\n",
    "            \n",
    "#             loss_d_fake.backward()\n",
    "#             D_G_z1 = output.mean().item()\n",
    "#             loss_d = loss_d_real + loss_d_fake\n",
    "\n",
    "#             optimizer.step()\n",
    "\n",
    "#             pbar.set_postfix(\n",
    "#                 OrderedDict(loss_d=loss_d.item())\n",
    "#             )\n",
    "        \n",
    "#         iters += 1\n",
    "#     torch.save(model_for_sampling.state_dict(), 'sep.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37dde1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (main): Sequential(\n",
       "    (0): ConvTranspose2d(500, 2048, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(2048, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (19): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = Generator(ngpu).to(device)\n",
    "generator.load_state_dict(torch.load('generator.pt'))\n",
    "\n",
    "discriminator = Discriminator(ngpu).to(device)\n",
    "discriminator.load_state_dict(torch.load('discriminator.pt'))\n",
    "# discriminator = timm.create_model('resnet18', num_classes=2).to(device)\n",
    "# discriminator.load_state_dict(torch.load('sep.pt'))\n",
    "\n",
    "discriminator.eval()\n",
    "generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "95a732c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:46<00:00, 21.72it/s]\n"
     ]
    }
   ],
   "source": [
    "bs = 32\n",
    "steps = 1000\n",
    "\n",
    "if not Path('generated').exists():\n",
    "    os.mkdir('generated')\n",
    "\n",
    "    \n",
    "cnt = 0\n",
    "for step in tqdm(range(steps)):\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(bs, nz, 1, 1, device=device)\n",
    "        images = generator(noise)\n",
    "        probs = discriminator(images)\n",
    "        \n",
    "        probs = probs.softmax(dim=1)\n",
    "#         labels = probs.argmax(dim=1).detach().cpu().numpy()\n",
    "        for i in range(bs):\n",
    "            if probs[i, 1] >= 0.6:\n",
    "                save_image(images[i, ...].permute(1, 2, 0).detach().cpu().numpy(), \n",
    "                           os.path.join('generated', str(cnt) + '.png'))\n",
    "                cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ad8f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b871eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
