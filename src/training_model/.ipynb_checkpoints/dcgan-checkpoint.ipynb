{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f89120d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from gan import Generator\n",
    "from gan import Discriminator\n",
    "from gan import weights_init\n",
    "from dataset import HandDataset\n",
    "import cv2\n",
    "import timm\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cac9454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>skinColor</th>\n",
       "      <th>accessories</th>\n",
       "      <th>nailPolish</th>\n",
       "      <th>aspectOfHand</th>\n",
       "      <th>imageName</th>\n",
       "      <th>irregularities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "      <td>fair</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dorsal right</td>\n",
       "      <td>Hand_0000002.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "      <td>fair</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dorsal right</td>\n",
       "      <td>Hand_0000003.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "      <td>fair</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dorsal right</td>\n",
       "      <td>Hand_0000004.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "      <td>fair</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dorsal right</td>\n",
       "      <td>Hand_0000005.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "      <td>fair</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dorsal right</td>\n",
       "      <td>Hand_0000006.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11071</th>\n",
       "      <td>1589</td>\n",
       "      <td>22</td>\n",
       "      <td>female</td>\n",
       "      <td>fair</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>palmar left</td>\n",
       "      <td>Hand_0011740.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11072</th>\n",
       "      <td>1589</td>\n",
       "      <td>22</td>\n",
       "      <td>female</td>\n",
       "      <td>fair</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>palmar left</td>\n",
       "      <td>Hand_0011741.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11073</th>\n",
       "      <td>1589</td>\n",
       "      <td>22</td>\n",
       "      <td>female</td>\n",
       "      <td>fair</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>palmar left</td>\n",
       "      <td>Hand_0011742.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11074</th>\n",
       "      <td>1589</td>\n",
       "      <td>22</td>\n",
       "      <td>female</td>\n",
       "      <td>fair</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>palmar left</td>\n",
       "      <td>Hand_0011743.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11075</th>\n",
       "      <td>1589</td>\n",
       "      <td>22</td>\n",
       "      <td>female</td>\n",
       "      <td>fair</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>palmar left</td>\n",
       "      <td>Hand_0011744.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11076 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  age  gender skinColor  accessories  nailPolish  aspectOfHand  \\\n",
       "0         0   27    male      fair            0           0  dorsal right   \n",
       "1         0   27    male      fair            0           0  dorsal right   \n",
       "2         0   27    male      fair            0           0  dorsal right   \n",
       "3         0   27    male      fair            0           0  dorsal right   \n",
       "4         0   27    male      fair            0           0  dorsal right   \n",
       "...     ...  ...     ...       ...          ...         ...           ...   \n",
       "11071  1589   22  female      fair            0           0   palmar left   \n",
       "11072  1589   22  female      fair            0           0   palmar left   \n",
       "11073  1589   22  female      fair            0           0   palmar left   \n",
       "11074  1589   22  female      fair            0           0   palmar left   \n",
       "11075  1589   22  female      fair            0           0   palmar left   \n",
       "\n",
       "              imageName  irregularities  \n",
       "0      Hand_0000002.jpg               0  \n",
       "1      Hand_0000003.jpg               0  \n",
       "2      Hand_0000004.jpg               0  \n",
       "3      Hand_0000005.jpg               0  \n",
       "4      Hand_0000006.jpg               0  \n",
       "...                 ...             ...  \n",
       "11071  Hand_0011740.jpg               0  \n",
       "11072  Hand_0011741.jpg               0  \n",
       "11073  Hand_0011742.jpg               0  \n",
       "11074  Hand_0011743.jpg               0  \n",
       "11075  Hand_0011744.jpg               0  \n",
       "\n",
       "[11076 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_path = 'archive/Hands/Hands'\n",
    "img_size = 256\n",
    "random_state = 69\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "z_size = 512\n",
    "\n",
    "df = pd.read_csv('archive/HandInfo.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "325a2702",
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = 4\n",
    "batch_size = 32\n",
    "image_size = 256\n",
    "nc = 3\n",
    "nz = 500\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "num_epochs = 300\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469ee2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YOLO('yolo11n.pt')\n",
    "yolo = yolo.to(device)\n",
    "\n",
    "res = yolo.train(data='/home/anton/PycharmProjects/another_projects/bio/hand-palm-detection.v2i.yolov11/data.yaml', epochs=200)\n",
    "\n",
    "results = yolo([os.path.join(ds_path, fn) for fn in os.listdir(ds_path)][:3])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd929ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5963219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    boxes = result.boxes\n",
    "    print(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea8b9e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 11076/11076 [04:59<00:00, 37.03it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path_to_model = '/home/anton/PycharmProjects/another_projects/bio/best.pt'\n",
    "best_yolo = YOLO(path_to_model)\n",
    "\n",
    "if not Path('cropped_images').exists():\n",
    "    os.mkdir('cropped_images')\n",
    "    \n",
    "all_fns = [os.path.join(ds_path, fn) for fn in os.listdir(ds_path)]\n",
    "\n",
    "for fn in tqdm(all_fns):\n",
    "    result = best_yolo.predict(fn, show=False, verbose=False)\n",
    "    boxes = result[0].boxes.xyxy\n",
    "    if len(boxes) > 0:\n",
    "        x1, y1, x2, y2 = list(map(int, boxes.detach().cpu().numpy()[0]))\n",
    "    \n",
    "        img_name = fn.split('/')[-1]\n",
    "        img = cv2.imread(fn)\n",
    "        \n",
    "        x1, x2 = max(int(x1 - 0.2 * img.shape[1]), 0), min(int(x2 + 0.2 * img.shape[1]), img.shape[1] - 2)\n",
    "        y1, y2 = max(int(y1 - 0.2 * img.shape[0]), 0), min(int(y2 + 0.2 * img.shape[0]), img.shape[0] - 2)\n",
    "        new_image = img[y1:y2+1, x1:x2+1]\n",
    "        cv2.imwrite(os.path.join('cropped_images', img_name), new_image)\n",
    "        continue\n",
    "    \n",
    "    image = cv2.imread(fn)\n",
    "    img_name = fn.split('/')[-1]\n",
    "    cv2.imwrite(os.path.join('cropped_images', img_name), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e350d420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed(random_state):\n",
    "    torch.manual_seed(random_state)\n",
    "    torch.cuda.manual_seed(random_state)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b55f4c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(timages, folder):\n",
    "    if not Path(folder).exists():\n",
    "        os.mkdir(folder)\n",
    "        \n",
    "    for nimage in range(timages.shape[0]):\n",
    "        timage = timages[nimage, ...]\n",
    "        image = timage.permute(1, 2, 0).detach().cpu().numpy()\n",
    "        cv2.imwrite(os.path.join(folder, str(nimage) + '.png'), image * 255)\n",
    "        \n",
    "        \n",
    "def save_image(image, image_path):\n",
    "    image *= 255\n",
    "    cv2.imwrite(image_path, image)\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((512, 512))\n",
    "    image = np.array(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(image_path, np.array(image))\n",
    "    \n",
    "def discriminator_loss_real(y_pred):\n",
    "    return torch.tensor(sum([math.log(y_pred[i, 1].item() + 1e-6) \n",
    "                for i in range(y_pred.shape[0])]) / y_pred.shape[0], requires_grad=True)\n",
    "\n",
    "def discriminator_loss_fake(y_pred):\n",
    "    return torch.tensor(sum([math.log(1 - y_pred[i, 1].item() + 1e-6)\n",
    "                for i in range(y_pred.shape[0])]) / y_pred.shape[0], requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e288d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = A.Compose([\n",
    "    A.Resize(img_size, img_size),\n",
    "#     A.VerticalFlip(p=0.6),\n",
    "#     A.HorizontalFlip(p=0.6),\n",
    "#     A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.6),\n",
    "#     A.Normalize(mean=0.5, std=0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a42f9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_path_ = 'cropped_images'\n",
    "dataset = HandDataset(ds_path_, df, transform=transforms)\n",
    "dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b240bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6db6460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "lr = 0.0002\n",
    "\n",
    "load = True\n",
    "\n",
    "generator = Generator(ngpu).to(device)\n",
    "# discriminator = timm.create_model('resnet18', pretrained=False, num_classes=2).to(device)\n",
    "discriminator = Discriminator(ngpu).to(device)\n",
    "weights_init(generator)\n",
    "weights_init(discriminator)\n",
    "\n",
    "if load:\n",
    "    generator.load_state_dict(torch.load('generator.pt'))\n",
    "    discriminator.load_state_dict(torch.load('discriminator.pt'))\n",
    "\n",
    "optimizer_gen = torch.optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizer_dis = torch.optim.Adam(discriminator.parameters(), lr=lr/2, betas=(beta1, 0.999))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c4a8093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 347/347 [02:49<00:00,  2.05it/s, loss_d=0.00117, loss_g=16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 347/347 [02:58<00:00,  1.94it/s, loss_d=9.09e-6, loss_g=24.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 347/347 [02:58<00:00,  1.94it/s, loss_d=0.000106, loss_g=15.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 347/347 [02:57<00:00,  1.95it/s, loss_d=0.0124, loss_g=9.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 347/347 [02:58<00:00,  1.95it/s, loss_d=0.0425, loss_g=9.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 347/347 [02:58<00:00,  1.94it/s, loss_d=0.119, loss_g=11.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 347/347 [02:58<00:00,  1.94it/s, loss_d=0.00628, loss_g=14.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 347/347 [02:58<00:00,  1.95it/s, loss_d=0.322, loss_g=10.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 347/347 [02:58<00:00,  1.95it/s, loss_d=0.00693, loss_g=11.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 347/347 [02:58<00:00,  1.95it/s, loss_d=0.000144, loss_g=14.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 347/347 [02:58<00:00,  1.94it/s, loss_d=0.605, loss_g=1.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 347/347 [02:58<00:00,  1.94it/s, loss_d=0.000299, loss_g=12.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████| 347/347 [02:57<00:00,  1.95it/s, loss_d=0.046, loss_g=12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 347/347 [02:57<00:00,  1.95it/s, loss_d=0.00164, loss_g=10.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 347/347 [02:58<00:00,  1.95it/s, loss_d=0.00754, loss_g=13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 347/347 [03:01<00:00,  1.91it/s, loss_d=0.886, loss_g=4.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████| 347/347 [03:14<00:00,  1.79it/s, loss_d=1.81, loss_g=1.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 347/347 [03:13<00:00,  1.79it/s, loss_d=0.00175, loss_g=11.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 347/347 [03:12<00:00,  1.81it/s, loss_d=3.67, loss_g=0.0372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 347/347 [03:11<00:00,  1.81it/s, loss_d=3.86, loss_g=0.000255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████| 347/347 [03:11<00:00,  1.81it/s, loss_d=0.104, loss_g=16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 347/347 [03:12<00:00,  1.80it/s, loss_d=6.26, loss_g=1.31e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 347/347 [03:12<00:00,  1.81it/s, loss_d=0.000111, loss_g=15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 347/347 [03:10<00:00,  1.82it/s, loss_d=0.0193, loss_g=16.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 347/347 [03:11<00:00,  1.81it/s, loss_d=0.501, loss_g=6.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 347/347 [03:10<00:00,  1.82it/s, loss_d=0.0014, loss_g=11.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 347/347 [03:12<00:00,  1.80it/s, loss_d=0.000227, loss_g=15.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████| 347/347 [03:10<00:00,  1.82it/s, loss_d=0.000192, loss_g=10.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████| 347/347 [03:11<00:00,  1.81it/s, loss_d=11.8, loss_g=5.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 347/347 [03:11<00:00,  1.81it/s, loss_d=0.00188, loss_g=9.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 347/347 [03:12<00:00,  1.80it/s, loss_d=0.00126, loss_g=13.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 347/347 [03:00<00:00,  1.92it/s, loss_d=0.025, loss_g=12.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████| 347/347 [03:03<00:00,  1.89it/s, loss_d=1.15, loss_g=3.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 347/347 [02:59<00:00,  1.94it/s, loss_d=0.0781, loss_g=7.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████| 347/347 [02:59<00:00,  1.93it/s, loss_d=0.0488, loss_g=16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 347/347 [02:58<00:00,  1.94it/s, loss_d=3.07e-6, loss_g=16.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 347/347 [03:09<00:00,  1.83it/s, loss_d=0.0226, loss_g=11.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 347/347 [02:58<00:00,  1.94it/s, loss_d=0.00639, loss_g=14.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 347/347 [02:58<00:00,  1.94it/s, loss_d=3.2, loss_g=0.0681]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 347/347 [02:58<00:00,  1.94it/s, loss_d=0.241, loss_g=11.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 347/347 [02:58<00:00,  1.94it/s, loss_d=6.34, loss_g=0.943]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 347/347 [02:57<00:00,  1.95it/s, loss_d=2.35e-5, loss_g=12.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 347/347 [02:57<00:00,  1.95it/s, loss_d=0.00443, loss_g=13.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 347/347 [02:58<00:00,  1.94it/s, loss_d=0.136, loss_g=13.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 347/347 [02:58<00:00,  1.95it/s, loss_d=0.00023, loss_g=14.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 347/347 [02:57<00:00,  1.95it/s, loss_d=0.0986, loss_g=11.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 347/347 [02:57<00:00,  1.95it/s, loss_d=8.34e-7, loss_g=14.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 347/347 [02:57<00:00,  1.96it/s, loss_d=0.0046, loss_g=8.96]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 347/347 [02:57<00:00,  1.95it/s, loss_d=0.501, loss_g=4.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 347/347 [02:57<00:00,  1.95it/s, loss_d=4.08e-6, loss_g=17.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 347/347 [02:58<00:00,  1.95it/s, loss_d=0.00338, loss_g=17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 347/347 [02:57<00:00,  1.96it/s, loss_d=3.76e-5, loss_g=12.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 347/347 [02:58<00:00,  1.94it/s, loss_d=5.59e-5, loss_g=12.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 347/347 [02:58<00:00,  1.94it/s, loss_d=2.98e-8, loss_g=19.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████| 347/347 [02:58<00:00,  1.94it/s, loss_d=1.77, loss_g=40.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 347/347 [02:57<00:00,  1.96it/s, loss_d=0.0167, loss_g=9.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 347/347 [02:58<00:00,  1.94it/s, loss_d=8.05e-7, loss_g=17.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 347/347 [02:58<00:00,  1.94it/s, loss_d=4.2e-6, loss_g=14.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████| 347/347 [02:58<00:00,  1.95it/s, loss_d=0.23, loss_g=3.78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 347/347 [02:59<00:00,  1.93it/s, loss_d=1.04e-6, loss_g=19.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████| 347/347 [03:00<00:00,  1.92it/s, loss_d=3.22, loss_g=0.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 347/347 [02:57<00:00,  1.96it/s, loss_d=8.28e-6, loss_g=12.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 347/347 [02:57<00:00,  1.96it/s, loss_d=2.21, loss_g=0.013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████| 347/347 [02:55<00:00,  1.97it/s, loss_d=4.57, loss_g=0.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████| 347/347 [02:55<00:00,  1.97it/s, loss_d=3.76, loss_g=1.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 347/347 [02:56<00:00,  1.97it/s, loss_d=1.49e-7, loss_g=16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████| 347/347 [02:56<00:00,  1.96it/s, loss_d=1.16, loss_g=2.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████| 347/347 [02:56<00:00,  1.97it/s, loss_d=1.15, loss_g=18.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████| 347/347 [02:57<00:00,  1.96it/s, loss_d=0.814, loss_g=14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 347/347 [02:56<00:00,  1.97it/s, loss_d=0.0832, loss_g=16.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████▎     | 168/347 [01:26<01:31,  1.95it/s, loss_d=0.000188, loss_g=13.3]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(dataloader, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader), position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pbar):\n\u001b[1;32m     15\u001b[0m         discriminator\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     17\u001b[0m         real_cpu \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/PycharmProjects/another_projects/bio/dataset.py:19\u001b[0m, in \u001b[0;36mHandDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m---> 19\u001b[0m     img_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[index][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimageName\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     20\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages_path, img_name))\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# img = Image.open(os.path.join(self.images_path, img_name)).convert('L')\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# img = img.convert('RGB')\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1754\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_integer(key, axis)\n\u001b[0;32m-> 1754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3996\u001b[0m, in \u001b[0;36mDataFrame._ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3994\u001b[0m \u001b[38;5;66;03m# irow\u001b[39;00m\n\u001b[1;32m   3995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 3996\u001b[0m     new_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mfast_xs(i)\n\u001b[1;32m   3998\u001b[0m     \u001b[38;5;66;03m# if we are a copy, mark as such\u001b[39;00m\n\u001b[1;32m   3999\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(new_mgr\u001b[38;5;241m.\u001b[39marray, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m new_mgr\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mbase \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:1001\u001b[0m, in \u001b[0;36mBlockManager.fast_xs\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    996\u001b[0m     result \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(result)\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;66;03m# Such assignment may incorrectly coerce NaT to None\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m     \u001b[38;5;66;03m# result[blk.mgr_locs] = blk._slice((slice(None), loc))\u001b[39;00m\n\u001b[0;32m-> 1001\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, rl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(blk\u001b[38;5;241m.\u001b[39mmgr_locs):\n\u001b[1;32m   1002\u001b[0m         result[rl] \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39miget((i, loc))\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "if not Path('gan_gen').exists():\n",
    "    os.mkdir('gan_gen')\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'epoch: {epoch + 1}')\n",
    "    with tqdm(dataloader, total=len(dataloader), position=0, leave=True) as pbar:\n",
    "        for i, data in enumerate(pbar):\n",
    "            discriminator.zero_grad()\n",
    "\n",
    "            real_cpu = data.to(device)\n",
    "\n",
    "            b_size = real_cpu.size(0)\n",
    "            label = torch.LongTensor([1 for j in range(b_size)]).to(device)\n",
    "\n",
    "            output = discriminator(real_cpu)\n",
    "\n",
    "            loss_d_real = criterion(output, label)\n",
    "\n",
    "            loss_d_real.backward()\n",
    "            D_x = output.mean().item()\n",
    "            noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "            fake = generator(noise)\n",
    "            label.fill_(fake_label)\n",
    "            output = discriminator(fake.detach())\n",
    "\n",
    "            loss_d_fake = criterion(output, label)\n",
    "            \n",
    "            loss_d_fake.backward()\n",
    "            D_G_z1 = output.mean().item()\n",
    "            loss_d = loss_d_real + loss_d_fake\n",
    "\n",
    "            optimizer_dis.step()\n",
    "\n",
    "            generator.zero_grad()\n",
    "            label.fill_(real_label) \n",
    "            output = discriminator(fake)\n",
    "            loss_g = criterion(output, label)\n",
    "    \n",
    "            loss_g.backward()\n",
    "            D_G_z2 = output.mean().item()\n",
    "            optimizer_gen.step()\n",
    "\n",
    "            pbar.set_postfix(\n",
    "                OrderedDict(loss_d=loss_d.item(),\n",
    "                           loss_g=loss_g.item())\n",
    "            )\n",
    "\n",
    "            G_losses.append(loss_g.item())\n",
    "            D_losses.append(loss_d.item())\n",
    "\n",
    "        if ((epoch == num_epochs-1) or (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = generator(fixed_noise).detach().cpu()\n",
    "                save_images(fake, 'gan_gen/sample_' + str(epoch))\n",
    "                \n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "        \n",
    "        iters += 1\n",
    "    torch.save(generator.state_dict(), 'generator.pt')\n",
    "    torch.save(discriminator.state_dict(), 'discriminator.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93bd571c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 347/347 [02:23<00:00,  2.42it/s, loss_d=0.0156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 347/347 [02:28<00:00,  2.33it/s, loss_d=0.00407]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████| 347/347 [02:29<00:00,  2.32it/s, loss_d=0.000308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████| 347/347 [02:30<00:00,  2.30it/s, loss_d=0.000457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████| 347/347 [02:30<00:00,  2.31it/s, loss_d=0.000145]\n"
     ]
    }
   ],
   "source": [
    "# generator = Generator(ngpu).to(device)\n",
    "# generator.load_state_dict(torch.load('generator.pt'))\n",
    "# generator.eval()\n",
    "# model_for_sampling = timm.create_model('resnet18', pretrained=True, num_classes=2).to(device)\n",
    "# optimizer = torch.optim.Adam(model_for_sampling.parameters(), lr=lr)\n",
    "\n",
    "# for epoch in range(5):\n",
    "#     print(f'epoch: {epoch + 1}')\n",
    "#     with tqdm(dataloader, total=len(dataloader), position=0, leave=True) as pbar:\n",
    "#         for i, data in enumerate(pbar):\n",
    "#             model_for_sampling.zero_grad()\n",
    "\n",
    "#             real_cpu = data.to(device)\n",
    "\n",
    "#             b_size = real_cpu.size(0)\n",
    "#             label = torch.LongTensor([1 for j in range(b_size)]).to(device)\n",
    "\n",
    "#             output = model_for_sampling(real_cpu)\n",
    "\n",
    "#             loss_d_real = criterion(output, label)\n",
    "\n",
    "#             loss_d_real.backward()\n",
    "#             D_x = output.mean().item()\n",
    "#             noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "#             fake = generator(noise)\n",
    "#             label.fill_(fake_label)\n",
    "#             output = model_for_sampling(fake.detach())\n",
    "\n",
    "#             loss_d_fake = criterion(output, label)\n",
    "            \n",
    "#             loss_d_fake.backward()\n",
    "#             D_G_z1 = output.mean().item()\n",
    "#             loss_d = loss_d_real + loss_d_fake\n",
    "\n",
    "#             optimizer.step()\n",
    "\n",
    "#             pbar.set_postfix(\n",
    "#                 OrderedDict(loss_d=loss_d.item())\n",
    "#             )\n",
    "        \n",
    "#         iters += 1\n",
    "#     torch.save(model_for_sampling.state_dict(), 'sep.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37dde1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (main): Sequential(\n",
       "    (0): ConvTranspose2d(500, 2048, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(2048, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (19): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = Generator(ngpu).to(device)\n",
    "generator.load_state_dict(torch.load('generator.pt'))\n",
    "\n",
    "discriminator = Discriminator(ngpu).to(device)\n",
    "discriminator.load_state_dict(torch.load('discriminator.pt'))\n",
    "# discriminator = timm.create_model('resnet18', num_classes=2).to(device)\n",
    "# discriminator.load_state_dict(torch.load('sep.pt'))\n",
    "\n",
    "discriminator.eval()\n",
    "generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "95a732c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [00:46<00:00, 21.72it/s]\n"
     ]
    }
   ],
   "source": [
    "bs = 32\n",
    "steps = 1000\n",
    "\n",
    "if not Path('generated').exists():\n",
    "    os.mkdir('generated')\n",
    "\n",
    "    \n",
    "cnt = 0\n",
    "for step in tqdm(range(steps)):\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(bs, nz, 1, 1, device=device)\n",
    "        images = generator(noise)\n",
    "        probs = discriminator(images)\n",
    "        \n",
    "        probs = probs.softmax(dim=1)\n",
    "#         labels = probs.argmax(dim=1).detach().cpu().numpy()\n",
    "        for i in range(bs):\n",
    "            if probs[i, 1] >= 0.6:\n",
    "                save_image(images[i, ...].permute(1, 2, 0).detach().cpu().numpy(), \n",
    "                           os.path.join('generated', str(cnt) + '.png'))\n",
    "                cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ad8f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b871eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
